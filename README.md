<div align="center">

# CrystalLens

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Made with Flask](https://img.shields.io/badge/Made%20with-Flask-000?logo=flask&logoColor=white)](#)
[![LLM: Ollama](https://img.shields.io/badge/LLM-Ollama-0b2a2a.svg)](#)
[![LLM: Gemini](https://img.shields.io/badge/LLM-Gemini-4285F4.svg)](#)

Evidence‚Äëdriven social media analysis for sensitive roles ‚Äî on‚Äëprem with Ollama or fast in the cloud with Gemini.

</div>


## ‚ú® Highlights
- **Employee & Accounts**: Manage employees and attach social accounts.
- **Scraping**: Start Twitter/Facebook scrapes via Apify with live job status.
- **AI Analysis**: Single‚Äërequest mode (fast) or staged evidence‚Üíassessment (robust).
- **Specific Assessments**: Political orientation, religious orientation, bias, personal issues, violence tendency, affiliation, suitability.
- **Reports**: Evidence‚Äëbacked narratives with citations, PDF export, CSV exports and dashboards.
- **RBAC & Auditing**: Roles for admin/manager/reviewer; audit log for sensitive actions.

## üì∏ Screenshots (placeholders)
Add your screenshots to `docs/` and reference them here.
- Dashboard
- Employee detail + Checks
- Analysis report + Specific Assessments

## üß≠ Architecture
```mermaid
flowchart LR
  A[UI (Flask templates)] --> B[Flask App]
  B --> C[Apify Service]
  B --> D[LLM Provider]
  D --> D1[Ollama]
  D --> D2[Gemini]
  B --> E[(DB)]
```

## üöÄ Quickstart (Dev)
1) Create a venv and install deps
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```
2) Configure `.env`
```bash
cp .env.example .env
# APIFY_API_TOKEN=...
# OLLAMA_API_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1:8b (or qwen2.5:7b-instruct)
# GOOGLE_API_KEY=... (for Gemini)
# ANALYSIS_PROVIDER=ollama|gemini
```
3) Seed an admin
```bash
python scripts/seed_admin.py
```
4) Run
```bash
python run.py
# http://127.0.0.1:5000
```

## ‚öôÔ∏è Configuration
- `DATABASE_URL`: PostgreSQL in prod (SQLite for dev is fine)
- `APIFY_API_TOKEN`: required for scraping
- `OLLAMA_API_URL`, `OLLAMA_MODEL`: for local LLM
- `GOOGLE_API_KEY`: for Gemini
- Set your provider in Settings or via `ANALYSIS_PROVIDER`

## ü§ñ Providers
- **Ollama (local)**: on‚Äëprem, best when data must not leave your infra
  - `ollama serve`, `ollama pull llama3.1:8b` (or `qwen2.5:7b-instruct`)
- **Gemini (cloud)**: fastest JSON formatting and latency
  - Enter `GOOGLE_API_KEY` in Settings; click ‚ÄúTest Gemini‚Äù

## üîí Security
- API keys in `.env` (not committed)
- Sensitive endpoints protected via RBAC
- Audit logs for critical actions

## üó∫Ô∏è Roadmap
- Detail level presets (speed vs. depth)
- Chunk‚Äëand‚Äësynthesize long timelines
- More providers (OpenAI, Claude) via adapter

## ü§ù Contributing
PRs welcome. Please open issues first for major changes. Keep secrets out of commits.

## üìÑ License
MIT ‚Äî see `LICENSE`.
